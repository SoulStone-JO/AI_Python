{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000                    # 迭代次数\n",
    "learning_rate = 0.001              # 学习率\n",
    "batch_size = 2000                  # 批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target)    # 利用方法切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15480, 8), (5160, 8), (15480,), (5160,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train) # 利用训练集的均值和方差做归一化，计算后放入scaler对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)            # 利用训练集的均方差来归一化     \n",
    "X_train = np.c_[np.ones((len(X_train), 1)), X_train]  # 截距项\n",
    "X_test = scaler.transform(X_test)              # 测试集也用训练集的均方差归一化，这样训练得出的结果运用更广\n",
    "X_test = np.c_[np.ones((len(X_test), 1)), X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant: 存放常量\n",
    "tf.Varible:  存放变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, name=\"X\")  #做SAD，每次传入数据不同，用placeholder\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"pred\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_op = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94733834]\n",
      " [ 0.5236051 ]\n",
      " [-0.515404  ]\n",
      " [-0.87315893]\n",
      " [ 0.90571404]\n",
      " [-0.4347322 ]\n",
      " [-0.3000939 ]\n",
      " [-0.53111005]\n",
      " [-0.48497963]]\n",
      "Epoch: 0 MSE: 2.9546108\n",
      "Epoch: 0 MSE: 3.730713\n",
      "[[ 1.7885376 ]\n",
      " [ 0.3053371 ]\n",
      " [-0.23682587]\n",
      " [-0.8687559 ]\n",
      " [ 0.82036483]\n",
      " [-0.18179576]\n",
      " [-0.05060455]\n",
      " [-0.4390741 ]\n",
      " [-0.4722213 ]]\n",
      "Epoch: 100 MSE: 1.4543846\n",
      "Epoch: 100 MSE: 1.5939736\n",
      "[[ 1.995391  ]\n",
      " [ 0.25063393]\n",
      " [-0.13904168]\n",
      " [-0.78846514]\n",
      " [ 0.76133347]\n",
      " [-0.08751462]\n",
      " [ 0.00301734]\n",
      " [-0.38519058]\n",
      " [-0.4237144 ]]\n",
      "Epoch: 200 MSE: 1.3395085\n",
      "Epoch: 200 MSE: 1.4498922\n",
      "[[ 2.0467684 ]\n",
      " [ 0.22575839]\n",
      " [-0.09750759]\n",
      " [-0.71318394]\n",
      " [ 0.6984721 ]\n",
      " [-0.05109901]\n",
      " [ 0.01141122]\n",
      " [-0.3385174 ]\n",
      " [-0.37545785]]\n",
      "Epoch: 300 MSE: 1.3144566\n",
      "Epoch: 300 MSE: 1.4217784\n",
      "[[ 2.0591745 ]\n",
      " [ 0.20681006]\n",
      " [-0.07683674]\n",
      " [-0.648827  ]\n",
      " [ 0.6344456 ]\n",
      " [-0.03547002]\n",
      " [ 0.01150053]\n",
      " [-0.29676867]\n",
      " [-0.33102393]]\n",
      "Epoch: 400 MSE: 1.2977308\n",
      "Epoch: 400 MSE: 1.4047031\n",
      "[[ 2.0623424 ]\n",
      " [ 0.18967801]\n",
      " [-0.06450082]\n",
      " [-0.5900502 ]\n",
      " [ 0.57677877]\n",
      " [-0.02761065]\n",
      " [ 0.0100363 ]\n",
      " [-0.25954476]\n",
      " [-0.29089636]]\n",
      "Epoch: 500 MSE: 1.2845954\n",
      "Epoch: 500 MSE: 1.3912944\n",
      "[[ 2.0631433 ]\n",
      " [ 0.17400134]\n",
      " [-0.05574813]\n",
      " [-0.5365402 ]\n",
      " [ 0.5249724 ]\n",
      " [-0.02319533]\n",
      " [ 0.0088709 ]\n",
      " [-0.22627418]\n",
      " [-0.25507867]]\n",
      "Epoch: 600 MSE: 1.2723367\n",
      "Epoch: 600 MSE: 1.3805513\n",
      "[[ 2.0630805 ]\n",
      " [ 0.1595462 ]\n",
      " [-0.04907314]\n",
      " [-0.4882804 ]\n",
      " [ 0.47787943]\n",
      " [-0.02004131]\n",
      " [ 0.00774686]\n",
      " [-0.19680104]\n",
      " [-0.22313827]]\n",
      "Epoch: 700 MSE: 1.2641371\n",
      "Epoch: 700 MSE: 1.3718307\n",
      "[[ 2.063619  ]\n",
      " [ 0.14634514]\n",
      " [-0.04333989]\n",
      " [-0.44503617]\n",
      " [ 0.43426982]\n",
      " [-0.01770766]\n",
      " [ 0.00694819]\n",
      " [-0.17076153]\n",
      " [-0.19474128]]\n",
      "Epoch: 800 MSE: 1.2565936\n",
      "Epoch: 800 MSE: 1.3648108\n",
      "[[ 2.063557  ]\n",
      " [ 0.13430615]\n",
      " [-0.03841822]\n",
      " [-0.4058425 ]\n",
      " [ 0.39492851]\n",
      " [-0.01575949]\n",
      " [ 0.00632743]\n",
      " [-0.14764352]\n",
      " [-0.16953069]]\n",
      "Epoch: 900 MSE: 1.2510127\n",
      "Epoch: 900 MSE: 1.3590785\n",
      "[[ 2.0635614 ]\n",
      " [ 0.12339575]\n",
      " [-0.03414647]\n",
      " [-0.3701613 ]\n",
      " [ 0.35915172]\n",
      " [-0.01398198]\n",
      " [ 0.00554776]\n",
      " [-0.12719508]\n",
      " [-0.14721087]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    n_batch = int(len(X_train)/batch_size)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            temp_theta = theta.eval()\n",
    "            print(temp_theta)\n",
    "            \n",
    "            print(\"Epoch:\",epoch,\"MSE:\",\n",
    "                 sess.run(mse, feed_dict={\n",
    "                    X:X_train,\n",
    "                    y:y_train\n",
    "                 }))\n",
    "            print(\"Epoch:\",epoch,\"MSE:\",\n",
    "                 sess.run(mse, feed_dict={\n",
    "                    X:X_test,\n",
    "                    y:y_test                      \n",
    "                 }))\n",
    "        arr = np.arange(len(X_train))\n",
    "        np.random.shuffle(arr)\n",
    "        X_train = X_train[arr]\n",
    "        y_train = y_train[arr]\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            sess.run(training_op,feed_dict={\n",
    "                X: X_train[i*batch_size: (i + 1)*batch_size],\n",
    "                y: y_train[i*batch_size: (i + 1)*batch_size]\n",
    "            })\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
